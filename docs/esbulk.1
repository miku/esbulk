.TH ESBULK 1 "JANUAR 2018" "Leipzig University Library" "Manuals"
.SH NAME
.PP
esbulk \- send documents to elasticsearch in bulk and in parallel.
.SH SYNOPSIS
.PP
\fB\fCesbulk\fR [\fB\fC\-server\fR \fIURL\fP, \fB\fC\-index\fR \fIname\fP, \fB\fC\-size\fR \fIN\fP, \fB\fC\-w\fR \fIN\fP, \fB\fC\-z\fR] < \fIfile\fP
.SH DESCRIPTION
.PP
esbulk takes as input a newline delimited JSON file and indexes all documents
into elasticsearch running on a given server address. The documents are batched
and indexed in parallel to achieve a high indexing throughput.
.PP
The newline delimited JSON text file format is explained at \[la]http://jsonlines.org/\[ra] and \[la]http://ndjson.org/\[ra]\&.
.SH OPTIONS
.TP
\fB\fC\-0\fR
Set the number of replicas to 0 during indexing (this can speed up indexing significantly, the original value is restored at the end and may cause delay until the cluster is green).
.TP
\fB\fC\-id\fR \fIstring\fP
Reuse value from this field as id. By default ids are autogenerated.
.TP
\fB\fC\-index\fR \fIstring\fP
Index name.
.TP
\fB\fC\-mapping\fR \fIfilename\fP
Mapping string or filename to apply before indexing.
.TP
\fB\fC\-p\fR \fIname\fP
Pipeline to use to preprocess documents.
.TP
\fB\fC\-purge\fR
Purge any existing index before reindexing. Warning: No confirmation required.
.TP
\fB\fC\-server\fR \fIURL\fP
SOLR hostport including schema like \[la]http://localhost:9200\[ra]
.TP
\fB\fC\-size\fR \fIN\fP
Batch size. Defaults to 1000. Increase for small documents.
.TP
\fB\fC\-type\fR \fIstring\fP
Elasticsearch type (deprecated in 6.0.0, \[la]https://is.gd/HFsOWt\[ra]). Default is "default".
.TP
\fB\fC\-u\fR \fIstring\fP
HTTP basic authentication "username:password" (like curl \-u).
.TP
\fB\fC\-v\fR
Program version.
.TP
\fB\fC\-verbose\fR
Show progress.
.TP
\fB\fC\-w\fR \fIN\fP
Number of workers. Defaults to number of cores.
.TP
\fB\fC\-z\fR
Decompress gzip input file on the fly.
.SH EXAMPLES
.PP
Index a compressed file:
.IP
\fB\fCesbulk \-index abc \-verbose \-server 110.81.131.200:9200 \-z file.ldj.gz\fR
.PP
Index from standard input:
.IP
\fB\fCcat file.ldj | esbulk \-index abc \-server 110.81.131.200:9200\fR
.PP
Purge an existing index, apply a mapping from a file and index:
.IP
\fB\fCesbulk \-purge \-mapping mapping.json \-index abc file.ldj\fR
.SH DIAGNOSITCS
.PP
If indexing pressure on the bulk API is too high (dozens or hundreds of
parallel workers, large batch sizes, depending on you setup), esbulk will halt
and report an error:
.PP
.RS
.nf
$ esbulk \-index my\-index\-name \-w 100 file.ldj
2017/01/02 16:25:25 error during bulk operation, try less workers (lower \-w value) or
increase thread_pool.bulk.queue_size in your nodes
.fi
.RE
.PP
Please note that, in such a case, some documents are indexed and some are not.
Your index will be in an INCONSISTENT STATE, since there is no transactional
bracket around the indexing process.
.PP
However, using defaults (parallism: number of cores) on a single node setup
will just work. For larger clusters, increase the number of workers until you
see full CPU utilization. After that, more workers won't buy any more speed.
.SH BUGS
.PP
Please report bugs to \[la]https://github.com/miku/esbulk/issues\[ra]\&.
.SH AUTHORS
.PP
Martin Czygan \[la]https://github.com/miku\[ra], \[la]martin.czygan@uni-leipzig.de\[ra]
sakshambathla \[la]https://github.com/sakshambathla\[ra]
Klaubert Herr \[la]https://github.com/klaubert\[ra]
Yusuke KUOKA \[la]https://github.com/mumoshu\[ra]
.SH SEE ALSO
.PP
FINC \[la]https://finc.info\[ra], AMSL \[la]http://amsl.technology/\[ra], solrbulk \[la]https://github.com/miku/solrbulk\[ra]
